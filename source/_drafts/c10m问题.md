---
title: c10m问题
tags: []
id: '1763'
categories:
  - - 系统架构
  - - system_arch
    - 高并发
---

之前我们讨论了C10K问题，现在nginx,node通过reactor模式已经能够提供c10k的能力。现在我们将问题扩展到C10M，这听起来有些不可思议，但是现在已经有系统在使用我们不太熟悉的方式提供了这种能力。

要了解C10M是如何做到的，我们有必要先了解一下Robert Graham在Shmoocon 2013大会上做的一篇演讲<<[C10M Defending The Internet At Scale](http://www.youtube.com/watch?v=73XNtI0w7jA#!)\>>.

在演讲中，Robert提出了一种全新的观点.

首先，他介绍了Unix的一点儿历史，指出Unix最初不是要设计为一种通用的OS，而是为了控制电话网络，数据是由电话网络进行传输的，控制和数据平面有着清晰的界限。问题是我们现在用Unix处理部分数据平面的工作，他认为这是不对的。为服务器只跑一个应用的场景设计内核和为支持多用户而设计内核是非常不同的。

因此，他认为问题的关键在于：

*   内核不是解决问题的方法，而是产生问题的根源。

也就是说内核不应该做繁重的工作。将数据包处理，内存管理，进程调度放到用户态来做，这样会更加高效。让Linux内核处理控制平面，而让应用处理数据平面。

这样系统就能够处理10m的并发连接，其中200个时钟用于数据包处理，14万个时钟用于处理应用逻辑。由于访问主存会消耗300个时钟，因此关键在于精简代码和减少缓存失效。

使用面向数据平面的系统每秒能够处理10m个数据包，而使用面向控制平面的系统每秒只能够处理1m个数据包。

这证明了一句老话：可扩展性就是定制化。要有显著地提高不能将性能外包给内核，而应该自己动手来做。

现在，我们来看下Robert是如何创造具有C10M能力的系统的。

C10K------过去10年的问题

过去10年里，工程师们通过修改内核(加入epoll)和将多线程程序(apache)改造为事件驱动的程序（nginx,node)解决了C10K问题。

Apache的问题

*   连接越多性能越差

*   可扩展性和性能不是同一个概念，人们讨论可扩展性时经常讨论性能，但这是2个不同的事情，正如apache的问题
*   对于1s的短暂连接事务，如果支持1000的TPS，那么就需要同时有1000个连接
*   如果每个事务执行10s,那么就需要10000个并发连接。这时Apache的性能会直线下跌，就像在遭受Dos攻击。只要进行大量的下载，Apache就会挂掉。
*   如果你要将每秒处理5000个连接的系统升级为每秒处理10000个连接，你会怎么做？你可能会升级硬件，将处理器能力提高1倍。但是你只是获得了双倍的性能，并没有获得双倍的扩展能力。现在你可能只能每秒处理6000个连接。如果你继续提升性能，问题仍然存在。16x的性能提升可能仍不能处理10K个连接。性能和可扩展性并不等同。
*   问题在于，apache会fork一个cgi程序，然后杀掉它，这种方式不具备可扩展性
*   为什么会这样？因为内核使用的O(n^2)算法

内核中的2个基本问题：

*   连接数=线程/进程数。数据包到来时，内核需要遍历所有10K个进程来判断将数据包交给谁处理。

*   连接数=select/poll(单线程）.和上面存在一样的问题。

解决方法：

*   无论线程个数多少，线程切换现在都是常数级的

*   加入epoll这种提供常数级的I/O查找的方式

线程切换不利于可扩展性，所以服务器软件nginx,node等使用epoll和异步编程模型。这和apache的性能曲线图完全不同，即使使用较低性能的服务器，在连接增多时性能也不会下降太快。

C10M-----下个十年的问题

C10M问题的挑战

1千万的并发连接